{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2206247f",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183acdda",
   "metadata": {},
   "source": [
    "#### for reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d5be6",
   "metadata": {},
   "source": [
    "## 1-Data preprocessing\n",
    "#### importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ad461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15212aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2292b",
   "metadata": {},
   "source": [
    "### Encoding categorical data\n",
    "###### Label the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d314be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8162ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce5be4",
   "metadata": {},
   "source": [
    "#### Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a294bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cc07d",
   "metadata": {},
   "source": [
    "### split the dataset into two sets trainingset and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe579c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0fba53",
   "metadata": {},
   "source": [
    "### Now feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab4a46",
   "metadata": {},
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d4419",
   "metadata": {},
   "source": [
    "#### Now initiating the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692ac19",
   "metadata": {},
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7677435",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f834fc5",
   "metadata": {},
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0c5bc",
   "metadata": {},
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf049b5",
   "metadata": {},
   "source": [
    "## 3 - Training the ANN\n",
    "#### Compilation of the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e712ad0",
   "metadata": {},
   "source": [
    "### Training of the ANN in the TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0487d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1a13a",
   "metadata": {},
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c153faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b683fd8",
   "metadata": {},
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76584366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9849d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
